# Path to training data in a format accepted by pandas (e.g. read_csv, read_hdf)
input:
    path : null
    # TODO: data, model, predictions, is_test_data

outputs:
    # Path to directory for saving all outputs
    path : null
    # Save all outputs in a timestamped subdirectory of `path`
    timestamp_subdir : false
    # Overwrite output directory if it exists. Otherwise, ask user.
    overwrite : false
    # Format in which to save models to disk
    # Choices: pkl, joblib, dill, cloudpickle, skops, onnx
    # User responsible for installing required 3rd party libraries
    model_format : pkl
    # Format in which to save pandas DataFrame and Series objects to disk
    # Choices: csv, json, html, xml, xlsx, hdf, feather, parquet, orc, stata, pkl
    #   - see https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html
    # User responsible for installing required 3rd party libraries
    pandas_format : feather
    # Format in which to save plots
    # Choices: see matplotlib.Figure.savefig
    image_format : png # Any format that can passed to matplotlib Figure.savefig
    # Toggles for which outputs to save
    toggles:
        # Reproducibility
        save_input_configs       : false
        save_final_config        : true
        save_git_diff            : false
        # Fitting
        save_test_scores         : true
        save_train_scores        : false
        save_estimators          : false
        save_test_predictions    : false
        save_train_predictions   : false
        save_indices             : false
        # Analysis
        save_feature_importances : false
        # Visualization
        save_confusion_matrix_plot       : false
        save_roc_curve_plot              : false
        save_det_curve_plot              : false
        save_predicion_recall_curve_plot : false
        save_calibration_plot            : false
        save_prediction_error_plot       : false
        save_partial_dependence_plot     : false
        save_decision_bounary_plot       : false
        save_learning_curve_plot         : false
        save_validation_curve_plot       : false
        save_feature_plots               : false


random_seed: 0

preprocess:
    astype     : null   # df = df.astype(astype)
    index      : null   # df = df.set_index(index)
    features   : null   # X = df[features]
    target     : target # y = df[target]
    target_map : null   # y = y.map(target_map)

# Value of target column to treat as positive class (only for classification)
pos_label : null

model_selector: null

# Configure the iteration over train-test folds.
# Option 1) Scikit-learn cross validator with all defaults
# train_test_iterator : KFold
# Option 2) Scikit-learn cross validator with keyword arguments
# train_test_iterator :
#     KFold:
#         n_splits: 10
train_test_iterator : train_test_split

train_on_all : false

# Names for splits used in DataFrame columns. 'null' results in simple
# enumeration.
split_names: 'split{}'

# Collapse predictions for each split into a single column (a.k.a.
# pd.DataFrame.stack) if possible. The common use case would be stacking
# predictions on test folds during cross validation into a single column of
# predictions given that the test folds partition the data. If test sets overlap
# across splits or training predictions are saved out alongside test
# predictions, then stacking is not possible as there are multiple predictions
# per row. In that case, this option is ignored.
stack_split_predictions: true


# TODO: Allow user to specify multiple estimators as a list or even "all Classifiers"
estimator: null

# Keyword arguments for model_selection.cross_validate
fit: null

visualization:
    # Classifier predict
    ConfusionMatrixDisplay  : null # see metrics.ConfusionMatrixDisplay.from_predictions()
    # Classifier proba
    RocCurveDisplay         : null # see metrics.RocCurveDisplay.from_predictions
    DetCurveDisplay         : null # see metrics.DetCurveDisplay.from_predictions
    PrecisionRecallDisplay  : null # see metrics.PrecisionRecallDisplay.from_predictions
    CalibrationDisplay      : null # see calibration.CalibrationDisplay
    # Regression predict
    PredictionErrorDisplay  : null # see metrics.PredictionErrorDisplay.from_predictions
    # Other
    PartialDependenceDisplay: null # see inspection.PartialDependenceDisplay.from_estimator
    DecisionBoundaryDisplay : null # see inspection.DecisionBoundaryDisplay.from_estimator
    LearningCurveDisplay    : null # see model_selection.LearningCurveDisplay.from_estimator
    ValidationCurveDisplay  : null # see model_selection.ValidationCurveDisplay.from_estimator

    roc:
        # TODO: simplify roc curve plotting functions
        facet_grid: null # kwargs for seaborn.facetgrid
        facet_grid_roc: null # kwargs for _facetgrid_plot_roc_curve
        bootstrap: null # kwargs for roc.bootstrap
        curve: null # kwargs for plot_roc_curve
        scaling:
        tp_count : null
        fp_count : null
    # TODO: Add other sklearn supported visualizations: confusion matrix, learning
    # curve, etc.

# Toggle what gets returned by fit_supervised_model()
# null -> determine automatically based on outputs to be saved
returns:
    return_y_true              : null
    return_test_scores         : null
    return_train_scores        : null
    return_estimators          : null
    return_test_predictions    : null
    return_train_predictions   : null
    return_indices             : null
    return_feature_importances : null

logging:
    # kwargs for logging.basicConfig()
    format : '%(levelname)8s | %(module)s :: %(message)s'
    level: INFO
    force: True
    filename : null #run.log
    filemode : w
    # kwargs for logging.dictConfig
    # dict_config: null
    #   Add below to temporarily change properties of a specific logger
    #   disable_existing_loggers: False
    #   loggers:
    #     skutils.prediction:
    #       level : 'DEBUG'
